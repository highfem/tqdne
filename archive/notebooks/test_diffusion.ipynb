{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful modules for notebooks\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# select GPU 1\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from tqdne.conf import DATASETDIR\n",
    "from pathlib import Path\n",
    "from tqdne.dataset import H5Dataset, RandomDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from diffusers import UNet1DModel\n",
    "from diffusers import DDPMScheduler\n",
    "from tqdne.diffusers import DDPMPipeline1DCond\n",
    "from tqdne.lightning import LightningDDMP, LogCallback\n",
    "\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from pathlib import Path\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from tqdne.conf import OUTPUTDIR, PROJECT_NAME\n",
    "\n",
    "import pytorch_lightning as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create very simple synthetic dataset\n",
    "\n",
    "t = (5501 // 32) * 32\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# path_train = DATASETDIR / Path(\"data_train.h5\")\n",
    "# path_test = DATASETDIR / Path(\"data_test.h5\")\n",
    "# train_dataset = H5Dataset(path_train, cut=t)\n",
    "# test_dataset = H5Dataset(path_test, cut=t)\n",
    "\n",
    "train_dataset = RandomDataset(1024*8, t=t)\n",
    "test_dataset = RandomDataset(512, t=t)\n",
    "\n",
    "channels = train_dataset[0][0].shape[0]\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4)\n",
    "channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_res, high_res = train_dataset[0]\n",
    "\n",
    "low_res.shape, high_res.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 100\n",
    "time = np.arange(0, t)/fs\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.plot(time ,low_res[0].numpy(), 'b', label=\"Input\")\n",
    "plt.plot(time, high_res[0].numpy(), 'r', label=\"Target\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.xlim(20, 30)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_low, batch_high = next(iter(train_loader))\n",
    "batch_low.shape, batch_high.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 50\n",
    "prediction_type = \"sample\" # `epsilon` (predicts the noise of the diffusion process) or `sample` (directly predicts the noisy sample`\n",
    "\n",
    "# Unet parameters\n",
    "unet_params = {\n",
    "    \"sample_size\":t,\n",
    "    \"in_channels\":channels*2, \n",
    "    \"out_channels\":channels,\n",
    "    \"block_out_channels\":  (32, 64, 128),\n",
    "    \"down_block_types\": ('DownBlock1D', 'DownBlock1D', 'AttnDownBlock1D'),\n",
    "    \"up_block_types\": ('AttnUpBlock1D', 'UpBlock1D', 'UpBlock1D'),\n",
    "    \"mid_block_type\": 'UNetMidBlock1D',\n",
    "    \"out_block_type\": \"OutConv1DBlock\",\n",
    "    \"extra_in_channels\" : 0,\n",
    "}\n",
    "\n",
    "scheduler_params = {\n",
    "    \"beta_schedule\": \"linear\",\n",
    "    \"beta_start\": 0.0001,\n",
    "    \"beta_end\": 0.02,\n",
    "    \"num_train_timesteps\": 1000,\n",
    "    \"prediction_type\": prediction_type, \n",
    "    \"clip_sample\": False,\n",
    "}\n",
    "\n",
    "optimizer_params = {\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"lr_warmup_steps\": 500,\n",
    "    \"n_train\": len(train_dataset) // batch_size,\n",
    "    \"seed\": 0,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"max_epochs\": max_epochs,\n",
    "}\n",
    "\n",
    "trainer_params = {\n",
    "    # trainer parameters\n",
    "    \"accumulate_grad_batches\": 1,\n",
    "    \"gradient_clip_val\": 1,\n",
    "    \"precision\": \"32-true\",  \n",
    "    # Double precision (64, '64' or '64-true'), full precision (32, '32' or '32-true'),\n",
    "    # 16bit mixed precision (16, '16', '16-mixed') or bfloat16 mixed precision ('bf16', 'bf16-mixed').\n",
    "    # Can be used on CPU, GPU, TPUs, HPUs or IPUs.\n",
    "    \"max_epochs\": max_epochs,\n",
    "    \"accelerator\": \"auto\",\n",
    "    \"devices\": \"auto\",\n",
    "    \"num_nodes\": 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net = UNet1DModel(**unet_params)\n",
    "net.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_inputs(low_res, high_res):\n",
    "    \"\"\"Build Unet inputs from low and high resolution data.\"\"\"\n",
    "    return torch.cat((low_res, high_res), dim=1)\n",
    "high_resn = torch.rand(batch_size, channels,t)\n",
    "\n",
    "inputs = to_inputs(batch_low, high_resn)\n",
    "timesteps = torch.LongTensor([150]*batch_size)\n",
    "print(inputs.shape)\n",
    "assert net(inputs, timesteps).sample.shape == batch_high.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = DDPMScheduler(**scheduler_params)\n",
    "scheduler.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(batch_high.shape)\n",
    "timesteps = torch.LongTensor([50]*batch_size)\n",
    "noisy_sig = scheduler.add_noise(batch_high, noise, timesteps)\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.plot(time, noisy_sig[0,0].numpy(), 'b', label=\"noisy\")\n",
    "plt.plot(time, batch_high[0,0].numpy(), 'r',  label=\"original\")\n",
    "plt.xlim(1, 5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this is probably wrong because of the conditioning\n",
    "# import tqdm\n",
    "\n",
    "# def sample(noise):\n",
    "#     sample = noise\n",
    "#     for i, t in enumerate(tqdm.tqdm(scheduler.timesteps)):\n",
    "#         # 1. predict noise residual\n",
    "#         with torch.no_grad():\n",
    "#             residual = net(sample, t).sample\n",
    "#         # 2. compute less noisy image and set x_t -> x_t-1\n",
    "#         sample = scheduler.step(residual, t, sample).prev_sample\n",
    "\n",
    "#     return sample\n",
    "\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# sample = train_dataset[0]\n",
    "# sig = sample.unsqueeze(0)\n",
    "# print(sig.shape)\n",
    "# noise = torch.randn(sig[:,:1].shape)\n",
    "# timesteps = torch.LongTensor([150])\n",
    "# noisy_sig = scheduler.add_noise(sig[:,:1], noise, timesteps)\n",
    "# noisy_sig = torch.concat([noisy_sig, sig[:,1:]], dim=1)\n",
    "# noise_pred = net(noisy_sig, timesteps).sample\n",
    "# loss = F.mse_loss(noise_pred, noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = DDPMPipeline1DCond(net, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(low_res, pipeline):\n",
    "#     # Sample some signaol from random noise (this is the backward diffusion process).\n",
    "#     sig = pipeline(\n",
    "#         low_res = low_res,\n",
    "#         generator=torch.manual_seed(optimizer_params[\"seed\"]),\n",
    "#     ).audios\n",
    "\n",
    "#     return sig\n",
    "\n",
    "# batch_low, batch_high = next(iter(train_loader))\n",
    "# gen_high = evaluate(batch_low, pipeline)\n",
    "\n",
    "# plt.plot(time, batch_high[0,0].numpy(), 'b', label=\"high res\")\n",
    "# plt.plot(time, batch_low[0,0].numpy(), 'r', label=\"low res\")\n",
    "# plt.plot(time, gen_high[0,0].numpy(), 'g', alpha=0.5, label=\"generated\")\n",
    "# plt.legend()\n",
    "# plt.xlim(1, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightningDDMP(net, scheduler, prediction_type=prediction_type, optimizer_params=optimizer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = next(iter(train_loader))\n",
    "\n",
    "# low_res, high_res = batch\n",
    "\n",
    "# # Sample noise to add to the high_res\n",
    "# noise = torch.randn(high_res.shape).to(high_res.device)\n",
    "# batch_size = high_res.shape[0]\n",
    "# # Sample a random timestep for each signal\n",
    "# timesteps = torch.randint(\n",
    "#     0,\n",
    "#     scheduler.config.num_train_timesteps,\n",
    "#     (batch_size,),\n",
    "#     device=high_res.device,\n",
    "# ).long()\n",
    "# timesteps[0] = 150\n",
    "\n",
    "# noisy_hig_res = scheduler.add_noise(high_res, noise, timesteps)\n",
    "\n",
    "# # Predict the noise residual\n",
    "# inputs = to_inputs(low_res, noisy_hig_res)\n",
    "# noise_pred = net(inputs, timesteps, return_dict=False)[0]\n",
    "\n",
    "# plt.figure(figsize=(6, 3))\n",
    "# plt.plot(time, low_res[0,0].numpy(), 'b', label=\"low res\")\n",
    "# plt.plot(time, high_res[0,0].numpy(), 'r', label=\"high res\")\n",
    "# plt.plot(time, noisy_hig_res[0,0].numpy(), 'g', label=\"noisy high res\", alpha=0.5)\n",
    "# plt.legend()\n",
    "# plt.xlim(1, 5)\n",
    "# plt.figure(figsize=(6, 3))\n",
    "# plt.plot(time, noise[0,0].numpy(), 'b', label=\"noise\", alpha=1)\n",
    "# plt.plot(time, noise_pred[0,0].detach().cpu().numpy(), 'g', label=\"predicted noise\")\n",
    "# plt.legend()\n",
    "# plt.xlim(1, 5)\n",
    "\n",
    "# noise_pred.min(), noise_pred.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '1D-UNET'\n",
    "\n",
    "# 1. Wandb Logger\n",
    "wandb_logger = WandbLogger(project=PROJECT_NAME) # add project='projectname' to log to a specific project\n",
    "\n",
    "# 2. Learning Rate Logger\n",
    "lr_logger = LearningRateMonitor()\n",
    "# 3. Set Early Stopping\n",
    "# early_stopping = EarlyStopping('val_loss', mode='min', patience=5)\n",
    "# 4. saves checkpoints to 'model_path' whenever 'val_loss' has a new min\n",
    "checkpoint_callback = ModelCheckpoint(dirpath=OUTPUTDIR / Path(name), filename='{name}_{epoch}-{val_loss:.2f}',\n",
    "                                      monitor='val_loss', mode='min', save_top_k=5)\n",
    "\n",
    "# 5. My custom callback\n",
    "log_callback = LogCallback(wandb_logger, test_loader)\n",
    "\n",
    "(OUTPUTDIR/Path(name)).mkdir(parents=True, exist_ok=True)\n",
    "# Define Trainer\n",
    "trainer = pl.Trainer(**trainer_params, logger=wandb_logger, callbacks=[lr_logger, log_callback, checkpoint_callback], \n",
    "                    default_root_dir=OUTPUTDIR/Path(name)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    low_res, high_res = next(iter(test_loader))\n",
    "    low_res = low_res.to(device)\n",
    "    high_res = high_res.to(device)\n",
    "\n",
    "    reconstructed = model.evaluate(low_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, c, t = reconstructed.shape\n",
    "fs = 100\n",
    "time = np.arange(0, t)/fs\n",
    "i = 0\n",
    "fig = plt.figure(figsize=(6, 3))\n",
    "plt.plot(time ,low_res[i,0].cpu().numpy(), 'b', label=\"Input\")\n",
    "plt.plot(time, high_res[i,0].cpu().numpy(), 'r', label=\"Target\")\n",
    "plt.plot(time, reconstructed[i,0].cpu().numpy(), 'g', alpha=0.5, label=\"Reconstructed\")\n",
    "plt.xlim(1, 5)\n",
    "plt.legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed.min(), reconstructed.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = net.device\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "low_res, high_res = batch\n",
    "\n",
    "with torch.no_grad():\n",
    "    low_res = low_res.to(device)\n",
    "    high_res = high_res.to(device)\n",
    "\n",
    "    # Sample noise to add to the high_res\n",
    "    noise = torch.randn(high_res.shape).to(high_res.device)\n",
    "    batch_size = high_res.shape[0]\n",
    "    # Sample a random timestep for each signal\n",
    "    timesteps = torch.randint(\n",
    "        0,\n",
    "        scheduler.config.num_train_timesteps,\n",
    "        (batch_size,),\n",
    "        device=high_res.device,\n",
    "    ).long()\n",
    "    timesteps[0] = 1\n",
    "\n",
    "    noisy_hig_res = scheduler.add_noise(high_res, noise, timesteps)\n",
    "\n",
    "    # Predict the noise residual\n",
    "    inputs = to_inputs(low_res, noisy_hig_res)\n",
    "    noise_pred = net(inputs, timesteps, return_dict=False)[0]\n",
    "\n",
    "    reconstructed_high_res = scheduler.step(\n",
    "        noise_pred[0], timesteps[0], noisy_hig_res[0], generator=None\n",
    "    ).prev_sample\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.plot(time, low_res[0,0].cpu().numpy(), 'b', label=\"low res\")\n",
    "plt.plot(time, high_res[0,0].cpu().numpy(), 'r', label=\"high res\")\n",
    "plt.plot(time, noisy_hig_res[0,0].cpu().numpy(), 'g', label=\"noisy high res\", alpha=0.5)\n",
    "plt.legend()\n",
    "plt.xlim(1, 5)\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.plot(time, noise[0,0].cpu().numpy(), 'b', label=\"noise\", alpha=1)\n",
    "plt.plot(time, noise_pred[0,0].detach().cpu().numpy(), 'g', label=\"predicted noise\")\n",
    "plt.legend()\n",
    "plt.xlim(1, 5)\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.plot(time, high_res[0,0].cpu().numpy(), 'b', label=\"high res\", alpha=1)\n",
    "plt.plot(time, reconstructed_high_res[0].detach().cpu().numpy(), 'g--', label=\"reconstructed\")\n",
    "# plt.plot(time, noisy_hig_res[0,0].cpu().numpy(), 'r', label=\"noisy high res\", alpha=0.5)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlim(1, 10)\n",
    "\n",
    "\n",
    "noise_pred.min(), noise_pred.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_high_res.max(), reconstructed_high_res.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tqdne-GZO51An4-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
