{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Report - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/fmachado/.cache/pypoetry/virtualenvs/tqdne-h7mN2Kd5-py3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/users/fmachado/.cache/pypoetry/virtualenvs/tqdne-h7mN2Kd5-py3.11/lib/python3.11/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdne.wgan_model import WDiscriminator, WGenerator\n",
    "from tqdne.gan import WGAN\n",
    "from tqdne.metric import PowerSpectralDensity, RepresentationInversion, SamplePlot\n",
    "from tqdne.representations import CenteredMaxEnvelope\n",
    "from tqdne.utils import load_model, get_last_checkpoint\n",
    "from tqdne.dataset import WaveformDataset\n",
    "from tqdne.conf import Config\n",
    "from tqdne.training import get_pl_trainer\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "**Generative Adversarial Networks (GANs)** have emerged as a groundbreaking paradigm in the field of deep learning, offering a powerful framework for generating realistic data samples from complex probability distributions. Introduced by Ian Goodfellow and his colleagues in 2014, GANs consist of two neural networks, namely the generator and the discriminator, engaged in a minimax game. The generator aims to produce synthetic data samples that are indistinguishable from genuine data, while the discriminator attempts to differentiate between real and fake samples. Through adversarial training, GANs learn to generate highly realistic data across various domains, including images, text, audio, and more.\n",
    "\n",
    "**Wasserstein GAN (WGAN)** represents a notable advancement in the GAN architecture. Unlike traditional GANs that rely on the Jensen-Shannon divergence or the Kullback-Leibler divergence for training, WGAN introduces the Wasserstein distance as the metric for measuring the discrepancy between the distributions of real and generated data. By optimizing the Wasserstein distance, WGANs offer improved stability and convergence properties compared to their predecessors, mitigating issues such as mode collapse and vanishing gradients commonly associated with traditional GAN training.\n",
    "\n",
    "In this project report, we delve into the application of Generative Adversarial Networks, particularly Wasserstein GANs, in the context of earthquake seismic wave simulation. By harnessing the capabilities of GANs and WGANs, we aim to develop models capable of generating synthetic seismic waveforms with high statistical resemblence to real-world observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Design\n",
    "\n",
    "### Generator and Discriminator\n",
    "\n",
    "We start by initializing the Generator and Discriminator of our GAN as below. We use four convolutional layers for both, with the Generator having and embedding layer for its latent space before the convolutional layers and the Discriminator having a fully connected layer after the convolutions to obtain its score.\n",
    "\n",
    "For the Generator each convolution followed by ReLU and a Batch Normalization layer. \n",
    "\n",
    "For the Discriminator each convolution is followed by LeakyReLU.\n",
    "\n",
    "The classes that implement the model are on `tqdne.wgan_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WGenerator(\n",
      "  (latent_to_features): Sequential(\n",
      "    (0): Linear(in_features=144, out_features=16384, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (features_to_signal): Sequential(\n",
      "    (0): ConvTranspose1d(256, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "    (7): ReLU()\n",
      "    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ConvTranspose1d(32, 1, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "G = WGenerator(\n",
    "    latent_dim=128,\n",
    "    wave_size=1024,\n",
    ")\n",
    "print(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WDiscriminator(\n",
      "  (image_to_features): Sequential(\n",
      "    (0): Conv1d(1, 32, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Conv1d(32, 64, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "    (3): LeakyReLU(negative_slope=0.2)\n",
      "    (4): Conv1d(64, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "    (5): LeakyReLU(negative_slope=0.2)\n",
      "    (6): Conv1d(128, 256, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "    (7): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (features_to_prob): Sequential(\n",
      "    (0): Linear(in_features=16400, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "D = WDiscriminator(\n",
    "    wave_size=1024,\n",
    ")\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding of Conditions:\n",
    "\n",
    "To account for the fact that we want to generate seismic data under certain conditions, namely the distance from the hypocenter and the magnitude, we have to add conditional information to our model. \n",
    "\n",
    "In particular, every waveform has a single scalar as `dist` and one as `mag`. We use positional encoding to add this information both to the Generator and Discriminator, although in slightly different ways.\n",
    "\n",
    "- *Generator:* We concatenate the positional embedding of the conditions with the latent space input of the Generator. This means the embedding goes through the fully connected and convolutional layers alongside the random sample from the latent space.\n",
    "\n",
    "- *Discriminator:* We concatenate the positional embedding of the conditions to the output of the block of convolutional layers. This means the conditions are only considered at the final fully connected layer of the discriminator.\n",
    "\n",
    "Both Generator and Discriminator accept a hyperparameter `encoding_L` to be the length used by the positional encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a complete set of hyperparameters, here it follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_parameters = {\n",
    "    \"latent_dim\": 128,\n",
    "    \"wave_size\": 1024,\n",
    "    \"out_channels\": 2, #Depends on the representation chosen\n",
    "    \"encoding_L\": 8,\n",
    "    \"num_cond_vars\": 2, #Mag and Dist\n",
    "    \"dim\": 32, #Controls the size of the convolution layers\n",
    "}\n",
    "discriminator_parameters = {\n",
    "    \"wave_size\": 1024,\n",
    "    \"in_channels\": 2, #Depends on the representation chosen\n",
    "    \"encoding_L\": 8,\n",
    "    \"num_cond_vars\": 2, #Mag and Dist\n",
    "    \"dim\": 32, #Controls the size of the convolution layers\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WGAN\n",
    "\n",
    "The Wasserstein GAN implemented in `tqdne.gan` is a PyTorch Lightning Module that initializates both Generator and Discriminator and coordinates the training. It takes care of the training, sampling, and all the interactions with the model. We use the Adam optimizer throughout the experiments.\n",
    "\n",
    "It notably has a common modification to GAN training by running one step of the Generator for each `n_critics` steps for the Discriminator, where `n_critics` is a hyperparameter. Moreover, we also have a hyperparameter `reg_lambda` that controls the multiplicative constant of the gradient penalty of the WGAN loss.\n",
    "\n",
    "For a full set of hyperparameters, refer below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_parameters = {\n",
    "    \"lr\": 1e-4,\n",
    "    \"b1\": 0.9,\n",
    "    \"b2\": 0.99,\n",
    "}\n",
    "model_parameters = {\n",
    "    \"reg_lambda\": 10.0,\n",
    "    \"n_critics\": 3,\n",
    "    \"optimizer_params\": optimizer_parameters,\n",
    "    \"generator_params\": generator_parameters,\n",
    "    \"discriminator_params\": discriminator_parameters,\n",
    "    \"conditional\": True, # Flag to use conditional WGAN\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 23:07:25 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmpmjqal04j\n",
      "2024-02-12 23:07:25 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmpmjqal04j/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "model = WGAN(**model_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs & Metrics\n",
    "\n",
    "Due to the limited performance of the approach so far, we limited the metrics of performance to visual inspection and negative critic loss, the latter being considered as a good indicator of convergence of a GAN.\n",
    "\n",
    "The metrics are automatically tracked on Weights & Biases, which is from where we take some of the visualizations below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics inherit from a standard interface `AbstractMetric` and allow for simple modularity. Each metric implements a update, compute and plot method, to obtain new data, compute the metric, and possibly plot it, respectively.\n",
    "\n",
    "More importantly, we heavily use a wrapper metric `RepresentationInversion` that is responsible for inverting the `Representation` transformation used for the dataset before computing or plotting the desired metric.\n",
    "\n",
    "Indeed, here it follows an example of how we use the metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation = CenteredMaxEnvelope(config)\n",
    "metrics = [PowerSpectralDensity(config.fs, channel=0), SamplePlot(config.fs, channel=0)]\n",
    "metrics = [RepresentationInversion(m, representation) for m in metrics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we also include the dataset, as it will be necessary for what comes next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = config.datasetdir / Path(config.data_upsample_train)\n",
    "test_path = config.datasetdir / Path(config.data_upsample_test)\n",
    "dataset_train = WaveformDataset(train_path, representation, reduced=1024)\n",
    "dataset_test = WaveformDataset(test_path, representation, reduced=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it only remains to load the Pytorch Lighning trainer and start it. Indeed, we have a helper function `get_pl_trainer` which configures and retuns our trainer but also attaches the logic for the handling of metrics to the trainer.\n",
    "It goes as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/fmachado/.cache/pypoetry/virtualenvs/tqdne-h7mN2Kd5-py3.11/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /users/fmachado/.cache/pypoetry/virtualenvs/tqdne-h7 ...\n",
      "2024-02-12 23:07:38 - pytorch_lightning.utilities.rank_zero - INFO - GPU available: False, used: False\n",
      "2024-02-12 23:07:38 - pytorch_lightning.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores\n",
      "2024-02-12 23:07:38 - pytorch_lightning.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs\n",
      "2024-02-12 23:07:38 - pytorch_lightning.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer_parameters = {\n",
    "    \"max_epochs\": 100,\n",
    "    \"accelerator\": \"auto\",\n",
    "    \"devices\": \"auto\",\n",
    "    \"log_every_n_steps\": 10,\n",
    "}\n",
    "trainer = get_pl_trainer(\n",
    "    name=\"Interactive WGAN\",\n",
    "    val_loader=DataLoader(dataset_test, batch_size=64),\n",
    "    metrics=metrics,\n",
    "    eval_every=10,\n",
    "    log_to_wandb=True,\n",
    "    config=config,\n",
    "    **trainer_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it remains to start training with the fit function, with the option of resuming the training that is automatically stored at the configured output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = False\n",
    "\n",
    "if resume:\n",
    "    last_checkpoint = get_last_checkpoint(config.outputdir / \"Interactive WGAN\")\n",
    "else:\n",
    "    last_checkpoint = None\n",
    "\n",
    "# trainer.fit(\n",
    "#     model,\n",
    "#     train_dataloaders=DataLoader(dataset_train, batch_size=64),\n",
    "#     test_dataloaders=DataLoader(dataset_test, batch_size=64),\n",
    "#     ckpt_path=last_checkpoint,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, we can just load the last checkpoint as done below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 23:07:38 - root - INFO - Last checkpoint is : /users/fmachado/tqdne/outputs/WGAN/name=0_epoch=47-val_loss=-24.74.ckpt\n"
     ]
    }
   ],
   "source": [
    "checkpoint = get_last_checkpoint(config.outputdir / \"WGAN\")\n",
    "model = WGAN.load_from_checkpoint(checkpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tqdne-h7mN2Kd5-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
