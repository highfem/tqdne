{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from obspy import Stream, Trace, UTCDateTime, read_inventory\n",
    "from obspy.core.trace import Stats\n",
    "from obspy.signal.trigger import recursive_sta_lta, trigger_onset\n",
    "from obspy.core.inventory import Inventory, Network, Station, Channel, Response\n",
    "from typing import Dict, Any, Union, List\n",
    "\n",
    "def merge_responses(sensor_response, datalogger_response):\n",
    "    # Assuming the datalogger response is to be appended to the sensor response stages\n",
    "    response_stages = sensor_response.response_stages + datalogger_response.response_stages\n",
    "    return Response(response_stages=response_stages)\n",
    "\n",
    "def adjust_station_name(sta, index):\n",
    "    sta_base = sta[:-1] if len(sta) > 4 else sta\n",
    "    new_sta = f\"{sta_base}{index}\"\n",
    "    if len(new_sta) > 5:\n",
    "        new_sta = f\"{sta_base[:-1]}{index}\"\n",
    "    return new_sta\n",
    "\n",
    "def save_seismogram(gen_data: Dict[str, Any], magnitude: float, net: Union[str, List[str]],\n",
    "                    sta: Union[str, List[str]], depth: float = 0.0, sampling_rate: float = 100.0,\n",
    "                    latitude: Union[float, List[float]] = 0.0, longitude: Union[float, List[float]] = 0.0,\n",
    "                    num_samples: int = 100, sensor_file: str = None, datalogger_file: str = None) -> None:\n",
    "    \"\"\"\n",
    "    Save seismogram data with station metadata to MiniSEED and STATIONXML files.\n",
    "    Parameters:\n",
    "    - gen_data: Dict containing 'waveforms' and 'cond'.\n",
    "    - magnitude: Magnitude of the event.\n",
    "    - depth: Depth of the event in kilometers.\n",
    "    - sampling_rate: Sampling rate of the seismogram in Hz.\n",
    "    - latitude: Latitude of the event (single value or list of values).\n",
    "    - longitude: Longitude of the event (single value or list of values).\n",
    "    - net: Network code (single value or list of values).\n",
    "    - sta: Station code (single value or list of values).\n",
    "    - num_samples: Number of samples.\n",
    "    - sensor_file: Path to the sensor XML file containing the response information.\n",
    "    - datalogger_file: Path to the datalogger XML file containing the response information.\n",
    "    \"\"\"\n",
    "    # Define trigger threshold\n",
    "    trigger_on = 1.5\n",
    "    trigger_off = 1.0\n",
    "    origin_time = UTCDateTime()\n",
    "    # Handle latitude and longitude input\n",
    "    num_waveforms = gen_data['waveforms'].shape[0]\n",
    "    latitudes = np.full(num_waveforms, latitude) if isinstance(latitude, (float, int)) else np.array(latitude)\n",
    "    longitudes = np.full(num_waveforms, longitude) if isinstance(longitude, (float, int)) else np.array(longitude)\n",
    "    stream = Stream()\n",
    "    inventory = Inventory(networks=[], source=\"HighFEM-user\")\n",
    "    # Read the responses from the sensor and datalogger XML files\n",
    "    if sensor_file:\n",
    "        sensor_inventory = read_inventory(sensor_file)\n",
    "    if datalogger_file:\n",
    "        datalogger_inventory = read_inventory(datalogger_file)\n",
    "    if isinstance(net, str):\n",
    "        net = [net] * num_waveforms\n",
    "    if isinstance(sta, str):\n",
    "        sta = [adjust_station_name(sta, i + 1) for i in range(num_waveforms)]\n",
    "    for it in range(num_waveforms):\n",
    "        network = Network(\n",
    "            code=net[it],\n",
    "            stations=[],\n",
    "            description=\"Station This Quake Does Not Exist network\",\n",
    "            start_date=origin_time - 3600*24*30  # station was deployed exactly a month before the earthquake\n",
    "        )\n",
    "        for i in range(it*num_samples, it*num_samples + num_samples):\n",
    "            # Station inventory\n",
    "            station = Station(\n",
    "                code=sta[it],\n",
    "                creation_date=origin_time - 3600*24*30,\n",
    "                latitude=latitudes[it],\n",
    "                longitude=longitudes[it],\n",
    "                elevation=gen_data['hypocentral_distance'][i],  # epi_distance\n",
    "                total_number_of_channels=3,\n",
    "                description=(\n",
    "                    f\"Shallow Crustal: {gen_data['is_shallow_crustal'][i]}, \"  # is shallow? 0 for not, 1 for yes\n",
    "                    f\"Vs30: {gen_data['vs30'][i]} m/s, \"  # vs30\n",
    "                    \"Elevation is hypocentral distance here\"  # add unit information\n",
    "                ),  # is shallow? 0 for not, 1 for yes\n",
    "                restricted_status=str(gen_data['vs30'][i])  # vs30\n",
    "            )\n",
    "            for j in range(gen_data['waveforms'].shape[1]):\n",
    "                # Define the onset of waveform\n",
    "                sta_lta_ratio = recursive_sta_lta(\n",
    "                    gen_data['waveforms'][i, j, :],\n",
    "                    int(1.5 * sampling_rate),\n",
    "                    int(4 * sampling_rate)\n",
    "                )\n",
    "                triggers = trigger_onset(sta_lta_ratio, trigger_on, trigger_off)\n",
    "                onset = np.amin(triggers) if len(triggers) > 0 else 0\n",
    "                time_onset = onset / sampling_rate\n",
    "                # Implement start time\n",
    "                Vp = 6.0  # km/s\n",
    "                est_distance = np.sqrt(gen_data['hypocentral_distance'][i]**2 + depth**2)\n",
    "                time_init = est_distance / Vp\n",
    "                # Stats\n",
    "                stats = Stats()\n",
    "                stats.network = net[it]\n",
    "                stats.station = sta[it]\n",
    "                stats.location = '00'\n",
    "                stats.calib = '1.0'\n",
    "                if j == 0:\n",
    "                    stats.channel = 'BHN' #high-freq virtual Z\n",
    "                elif j == 1:\n",
    "                    stats.channel = 'BHE' #high-freq virtual N\n",
    "                elif j == 2:\n",
    "                    stats.channel = 'BHZ' #high-freq virtual E\n",
    "                stats.sampling_rate = sampling_rate\n",
    "                stats.npts = gen_data['waveforms'][i, j, :].shape[0]\n",
    "                stats.starttime = origin_time + time_init - time_onset\n",
    "                stats['units'] = 'm/s^2'\n",
    "                # Trace data\n",
    "                trace = Trace(data=gen_data['waveforms'][i, j, :], header=stats)\n",
    "                stream.append(trace)\n",
    "                # Channel inventory\n",
    "                channel = Channel(\n",
    "                    code=stats.channel,\n",
    "                    location_code=\"00\",\n",
    "                    sample_rate=sampling_rate,\n",
    "                    latitude=latitudes[it],\n",
    "                    longitude=longitudes[it],\n",
    "                    elevation=gen_data['hypocentral_distance'][i],  # epi_distance\n",
    "                    depth=0.0,\n",
    "                    description=\"Amplitude in m/s^2\"\n",
    "                )\n",
    "                # Add the merged response to the channel\n",
    "                if sensor_file and datalogger_file:\n",
    "                    sensor_response = sensor_inventory[0][0][0].response\n",
    "                    datalogger_response = datalogger_inventory[0][0][0].response\n",
    "                    merged_response = merge_responses(sensor_response, datalogger_response)\n",
    "                    channel.response = merged_response\n",
    "                station.channels.append(channel)\n",
    "            network.stations.append(station)\n",
    "        inventory.networks.append(network)\n",
    "    # Save everything\n",
    "    output_file = f\"data_gm0/HighFEM_tqdne_{magnitude}_Japan\"\n",
    "    stream.write(output_file + \".mseed\", format='MSEED')\n",
    "    inventory.write(output_file + \".xml\", format='STATIONXML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "sensor_file = 'EEW/GenericUnitySensor.xml'\n",
    "datalogger_file = 'EEW/GenericUnityDataLogger.xml'\n",
    "save_seismogram(files, magnitude=mag, depth=depth, sampling_rate=100, latitude=lat, longitude=lon, net='HF', sta='HFEM', num_samples=1, sensor_file=sensor_file, datalogger_file=datalogger_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from obspy import read, read_inventory\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib import cm\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "plt.rc('font', family='serif')\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "# INPUT\n",
    "traces = read(\"data_gm0/HighFEM_tqdne_5.232177479920197_Japan.mseed\")\n",
    "inv = read_inventory(\"data_gm0/HighFEM_tqdne_5.232177479920197_Japan.xml\")\n",
    "scale = 50\n",
    "ntraces = 25\n",
    "# Colormap\n",
    "cmap = cm.plasma\n",
    "def select_maximally_spaced_values(values, n):\n",
    "    if n > len(values):\n",
    "        raise ValueError(\"n cannot be greater than the number of elements in the list\")\n",
    "    # Initialize the result list with the first and last elements\n",
    "    result = [0]\n",
    "    step = len(values) / (n - 1)\n",
    "    for i in range(1, n - 1):\n",
    "        idx = int(round(i * step))\n",
    "        result.append(idx)\n",
    "    result.append(-1)\n",
    "    return result\n",
    "for tr in traces:\n",
    "    # Get epicentral distance from stationxml\n",
    "    tr.stats.network = \"HF\"\n",
    "    dist = inv.get_channel_metadata(tr.id)[\"elevation\"]\n",
    "    # Add epicentral distance in meters\n",
    "    tr.stats.distance = 1000. * dist\n",
    "    tr.stats.vs30 = float(inv.select(station=tr.stats.station)[0][0].restricted_status)\n",
    "# Trim all to one starttime\n",
    "traces.trim(starttime=min([tr.stats.starttime for tr in traces]), endtime=max([tr.stats.endtime for tr in traces]), pad=True, fill_value=0.)\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "# Normalize the vs30 values\n",
    "norm = mcolors.Normalize(vmin=min([tr.stats.vs30 for tr in traces]), vmax=0.75 * max([tr.stats.vs30 for tr in traces]))\n",
    "norm = mcolors.Normalize(vmin=100, vmax=900)\n",
    "# Generate colors based on the normalized values\n",
    "colors = cmap(norm([tr.stats.vs30 for tr in traces]))\n",
    "# Choose traces well distributed over distance\n",
    "distances = [tr.stats.distance for tr in traces]  # in m\n",
    "t_offset_guessed_1 = min(distances) / 6000.  # time 0 should be time of P-wave\n",
    "t_offset_guessed_2 = 500 / traces[0].stats.sampling_rate # minus the pre-event time\n",
    "t_offset = t_offset_guessed_1 - t_offset_guessed_2\n",
    "ixs = select_maximally_spaced_values(distances, n=ntraces)\n",
    "for ix in ixs:\n",
    "    tr = traces[ix]\n",
    "    t = np.linspace(t_offset, t_offset + (tr.stats.npts - 1) * tr.stats.delta, tr.stats.npts)\n",
    "    plt.plot(t, tr.data * scale + tr.stats.distance / 1000., color=colors[ix], alpha=0.8, linewidth=0.8)\n",
    "# Add reference lines\n",
    "h2, = plt.plot(t, t * 6., \":\", color=\"k\")\n",
    "h3, = plt.plot(t, t * 3.3, \"--\", color=\"k\")\n",
    "plt.legend([h2, h3], [r\"V$_P$=6 km/s\", r\"V$_S$=3.3 km/s\"])\n",
    "# Create a ScalarMappable object for the colorbar\n",
    "sm = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])  # We don't need data for the colorbar\n",
    "# Add the colorbar\n",
    "cbar = fig.colorbar(sm, ax=ax)\n",
    "cbar.set_label('V$_{S30}$ [m/s]')\n",
    "plt.xlim(0, t.max())\n",
    "plt.ylim(min(distances) / 1000. * 0.5, max(distances) / 1000. * 1.1)\n",
    "plt.xlabel(\"Time after origin [s]\")\n",
    "plt.ylabel(\"Scaled waveform at distance [km]\")\n",
    "plt.savefig(\"figures/section_test.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
