{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GM0 Performance Evaluation\n",
    "\n",
    "**IMPORTANT**: This notebook should be used as a base for the evaluation of different models. \n",
    "\n",
    "- Please **make a copy of this notebook** whenever you want to evaluate a model. Load the desired model by changing the following `model_path_str` variable. \n",
    "- This notebook is currently not saving any generated plot. Please make sure to not overwrite the outputs, or to save the plots whenever needed. \n",
    "- This notebook saves the generated data. Please refer to the Evaluation section of this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available models on the SDSC shared folder: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /store/sdsc/sd28/models/GM0/diffusion/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = \"/store/sdsc/sd28/models/GM0/diffusion/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can either choose a specific checkpoint of a model or the most recent checkpoint of that model (default):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the last checkpoint of the model\n",
    "model_path_str = dataset_folder + \"ddim-pred:sample-1D-downsampling:2_SignalWithEnvelope-moving_average_shifted-log-log_offset:1.0e-05-normalize-scalar:True\"\n",
    "\n",
    "# Or pick a specific checkpoint\n",
    "# model_path_str = dataset_folder + \"/ddim-pred:sample-1D-downsampling:2_SignalWithEnvelope-moving_average_shifted-log-log_offset:1.0e-05-normalize-scalar:True/name=0_epoch=125-val_loss=0.02.ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the needed libraries, modules and needed variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdne.utils import *\n",
    "from tqdne.conf import Config\n",
    "from tqdne.metric import *\n",
    "\n",
    "from tqdne.dataset import EnvelopeDataset \n",
    "from torch.utils.data import DataLoader, ConcatDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    torch.cuda.empty_cache()\n",
    "else: \n",
    "    device = torch.device('cpu')\n",
    "\n",
    "torch.cuda.is_available(), device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "\n",
    "# Select the signal length\n",
    "signal_length = config.signal_length \n",
    "\n",
    "# Set the sampling frequency\n",
    "fs = config.fs\n",
    "\n",
    "# Set the number of channels of the original waveforms  \n",
    "n_channels = config.num_channels\n",
    "\n",
    "# Set the conditioning parameters range\n",
    "cond_params_range = config.conditional_params_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, model_data_repr, ckpt = load_model(Path(model_path_str), use_ddim=False)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print_model_info(model, model_data_repr, ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore the sampling rate and signal length that were used during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"downsampling\" in model_path_str:\n",
    "    downsampling = int(model_path_str.split(\"downsampling:\")[1].split(\"_\")[0])\n",
    "    fs = fs // downsampling\n",
    "    signal_length = signal_length // downsampling\n",
    "    config.signal_length = signal_length\n",
    "    config.fs = fs\n",
    "    print(f\"Updated signal length: {config.signal_length} and fs: {config.fs}\")\n",
    "else:\n",
    "    downsampling = 1    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the batch size.\n",
    "batch_size = model.hparams.optimizer_params.batch_size\n",
    "\n",
    "# One can also choose the batch size\n",
    "# batch_size = 32\n",
    "\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert values for the conditional input parameters.\n",
    "# Please read generate_cond_inputs documentation (in utils.py) to understand the structure of cond_input_params dictionary\n",
    "cond_input_params = {\n",
    "    \"hypocentral_distance\": [10, 100, 150],\n",
    "    \"is_shallow_crustal\": [0],\n",
    "    \"magnitude\": [5.5, 4, 7, 8.5],\n",
    "    \"vs30\": None,\n",
    "}\n",
    "\n",
    "data_raw = generate_data(model, model_data_representation=model_data_repr, raw_output=True, num_samples=batch_size, cond_input_params=cond_input_params, device=device.type, max_batch_size=batch_size)\n",
    "data_raw['waveforms'].shape, data_raw['cond'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw_wf = data_raw['waveforms']\n",
    "data_raw_wf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wf = model_data_repr.invert_representation(data_raw_wf)\n",
    "data_wf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Sample Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's investigate model's raw output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 0\n",
    "plot_raw_waveform(data_raw_wf[sample_index], data_raw['cond'][sample_index], model_data_repr, data_wf[sample_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 3\n",
    "plot_raw_waveform(data_raw_wf[sample_index], data_raw['cond'][sample_index], model_data_repr, data_wf[sample_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 10\n",
    "plot_raw_waveform(data_raw_wf[sample_index], data_raw['cond'][sample_index], model_data_repr, data_wf[sample_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: works only for 1D signals, need to generalize to 2D signals. However, is only useful for 1D signals.\n",
    "# max_peak_index = np.argmax(np.max(np.abs(data_raw_wf), axis=(1, 2)))\n",
    "# plot_raw_waveform(data_raw_wf[max_peak_index], n_channels, data_wf[max_peak_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now see the generated waveforms, along with their Power Spectral Density and Log Envelope. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"waveforms\": data_wf, \"cond\": data_raw['cond']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_waveform_and_psd(get_samples(data, num_samples=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_waveform_and_psd(get_samples(data, indexes=[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_waveforms(get_samples(data, num_samples=3), channel_index=0, plot_log_envelope=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_waveforms(get_samples(data, num_samples=2), channel_index=0, plot_log_envelope=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_bins(data, num_magnitude_bins=3, num_distance_bins=3, plot_type='waveform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_bins(data, num_magnitude_bins=3, num_distance_bins=3, plot_type='log_envelope')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_bins(data, num_magnitude_bins=3, num_distance_bins=3, plot_type='power_spectral_density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data\n",
    "del data_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdne.representations import Signal\n",
    "\n",
    "test_dataset_path = config.datasetdir / config.data_test\n",
    "train_dataset_path = config.datasetdir / config.data_train\n",
    "\n",
    "test_dataset = EnvelopeDataset(test_dataset_path, Signal(), cut=config.signal_length*downsampling, downsample=downsampling)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "train_dataset = EnvelopeDataset(train_dataset_path, Signal(), cut=config.signal_length*downsampling, downsample=downsampling)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "real_dataset = ConcatDataset([train_dataset, test_dataset])\n",
    "real_dataloader = DataLoader(real_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate couple of samples with the same conditioning parameters to check the expressiveness of the model and check if it lies within the true data distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_bin = (6, 6.5)\n",
    "dist_bin = (50, 70)\n",
    "data_test_single_bin = test_dataset.get_data_by_bins(mag_bin, dist_bin, is_shallow_crustal=0)\n",
    "cond_params_mean = np.mean(data_test_single_bin['cond'], axis=0).reshape(1,-1)\n",
    "data_pred_single_bin = generate_data(model, model_data_representation=model_data_repr, raw_output=False, num_samples=7, cond_input=cond_params_mean, device=device.type, max_batch_size=batch_size)\n",
    "\n",
    "plot_waveforms(data_pred_single_bin, test_waveforms=data_test_single_bin['waveforms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_bin = (4, 5)\n",
    "dist_bin = (120, 150)\n",
    "data_test_single_bin = test_dataset.get_data_by_bins(mag_bin, dist_bin, is_shallow_crustal=0)\n",
    "cond_params_mean = np.mean(data_test_single_bin['cond'], axis=0).reshape(1,-1)\n",
    "data_pred_single_bin = generate_data(model, model_data_representation=model_data_repr, raw_output=False, num_samples=7, cond_input=cond_params_mean, device=device.type, max_batch_size=batch_size)\n",
    "\n",
    "plot_waveforms(data_pred_single_bin, test_waveforms=data_test_single_bin['waveforms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_bin = (6.5, 9.)\n",
    "dist_bin = (120, 150)\n",
    "data_real_single_bin = test_dataset.get_data_by_bins(mag_bin, dist_bin, is_shallow_crustal=0)\n",
    "cond_params_mean = np.mean(data_real_single_bin['cond'], axis=0).reshape(1,-1)\n",
    "data_pred_single_bin = generate_data(model, model_data_representation=model_data_repr, raw_output=False, num_samples=7, cond_input=cond_params_mean, device=device.type, max_batch_size=batch_size)\n",
    "\n",
    "plot_waveforms(data_pred_single_bin, test_waveforms=data_real_single_bin['waveforms'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now compare the statistics of the generated data wrt the real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = {\n",
    "    \"waveforms\": np.concatenate([test_dataset.get_waveforms(), train_dataset.get_waveforms()], axis=0),\n",
    "    \"cond\": np.concatenate([test_dataset.features, train_dataset.features], axis=0)\n",
    "}\n",
    "real_data['waveforms'].shape, real_data['cond'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate more samples to perform an analysis by dividing the data in bins (magnitude and distance). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the generated data future use.\n",
    "\n",
    "The data will be saved as a `dict` with keys `waveforms` and `cond` in the same place of the checkpoint of the selected model, with the same name of `ckpt`, except for the extension of the file (saved as a HDF5 `.hdf5` file).\n",
    "The optimal approach for downloading the generated dataset to a local storage location is to replace the string `hdf5_filename` with the desired filename, thus enabling the file to be stored in the current directory. This file may then be downloaded via the integrated visual interface of VSCode or JupyterLab. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the generated waveforms along with the conditioning parameters\n",
    "hdf5_filename = f\"{str(ckpt).replace('.ckpt', '.hdf5')}\"\n",
    "hdf5_filepath = Path(hdf5_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate waveforms with the same conditioning parameters of the real data\n",
    "generated_raw_data = generate_data(\n",
    "    model, \n",
    "    model_data_repr, \n",
    "    raw_output=True, \n",
    "    num_samples=real_data['waveforms'].shape[0], \n",
    "    cond_input=real_data['cond'], \n",
    "    device=device.type, \n",
    "    save_path=hdf5_filepath\n",
    ")\n",
    "\n",
    "generated_raw_data['waveforms'].shape, generated_raw_data['cond'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the raw outputs by comparing them statistically with real data in the representation domain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_raw_output_distribution(generated_raw_data[\"waveforms\"], real_dataset.waveforms, model_data_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if generated_data is available\n",
    "if 'generated_data' in locals():\n",
    "    generated_data = {\"waveforms\": model_data_repr.invert_representation(generated_raw_data['waveforms']), \"cond\": generated_raw_data['cond']}\n",
    "    del generated_raw_data\n",
    "    # if samples are available in a preexisting file, append the new samples to generated_data\n",
    "    if hdf5_filepath.exists():\n",
    "        with h5py.File(hdf5_filepath, 'r') as f:\n",
    "            generated_data = {k: np.concatenate([generated_data[k], f[k][:]], axis=0) for k in generated_data.keys()}\n",
    "else:\n",
    "    # load the file hdf5_filename\n",
    "    with h5py.File(hdf5_filepath, 'r') as f:\n",
    "        generated_data = {\"waveforms\": f['waveforms'][:], \"cond\": f['cond'][:]}\n",
    "\n",
    "generated_data['waveforms'].shape, generated_data['cond'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's now compare the generated data against the real ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_bins = [(0, 40), (40, 60), (60, 80), (80.0, 120.), (120., 150.), (150., 200.)]\n",
    "magnitude_bins = [(4.5, 5.0), (5., 5.5), (5.5, 6.0), (6.0, 7.0), (7.0, 9.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bins(\n",
    "    plot_type='log_envelope',\n",
    "    distance_bins=distance_bins,\n",
    "    magnitude_bins=magnitude_bins,\n",
    "    channel_index=0,\n",
    "    test_data=real_data, \n",
    "    data=generated_data, \n",
    "    model=model,\n",
    "    model_data_representation = model_data_repr\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bins(\n",
    "    plot_type='power_spectral_density',\n",
    "    distance_bins=distance_bins,\n",
    "    magnitude_bins=magnitude_bins,\n",
    "    channel_index=0,\n",
    "    test_data=real_data, \n",
    "    data=generated_data, \n",
    "    model=model,\n",
    "    model_data_representation=model_data_repr\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the whole distribution in terms of Power Spectral Density and Envelope. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdne.plot import PowerSpectralDensityPlot, BinPlot\n",
    "from tqdne.metric import PowerSpectralDensity\n",
    "\n",
    "psd_metrics = [PowerSpectralDensity(fs, channel=channel, invert_representation=False) for channel in range(n_channels)]\n",
    "psd_plots = [PowerSpectralDensityPlot(fs, channel, invert_representation=False) for channel in range(n_channels)]\n",
    "for i, psd in enumerate(psd_metrics):\n",
    "    psd_plots[i](preds=generated_data['waveforms'], target=real_data['waveforms'][:, :, :signal_length])\n",
    "    psd(preds=generated_data['waveforms'], target=real_data['waveforms'][:, :, :signal_length])    \n",
    "    psd_bin = BinPlot(psd, num_mag_bins=10, num_dist_bins=10)\n",
    "    psd_bin(preds=generated_data, target={\"waveforms\": real_data['waveforms'], \"cond\": real_data['cond']})\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdne.plot import LogEnvelopePlot\n",
    "from tqdne.metric import LogEnvelope\n",
    "\n",
    "logenv_metrics = [LogEnvelope(channel=channel, invert_representation=False) for channel in range(n_channels)]\n",
    "logenv_plots = [LogEnvelopePlot(fs, channel, invert_representation=False) for channel in range(n_channels)]\n",
    "for i, logenv in enumerate(logenv_metrics):\n",
    "    logenv_plots[i](preds=generated_data['waveforms'], target=real_data['waveforms'][:, :, :signal_length])\n",
    "    logenv(preds=generated_data['waveforms'], target=real_data['waveforms'][:, :, :signal_length])    \n",
    "    logenv_bin = BinPlot(psd, num_mag_bins=10, num_dist_bins=10)\n",
    "    logenv_bin(preds=generated_data, target={\"waveforms\": real_data['waveforms'], \"cond\": real_data['cond']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation using a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_path = Path(\"/users/abosisio/scratch/tqdne/outputs/classifier-2D-32Chan-(1, 2, 4, 8)Mult-2ResBlocks-4AttHeads_LogSpectrogram-stft_ch:128-hop_size:32/name=0_epoch=19-val_loss=1.02.ckpt\")\n",
    "classifier, classifier_data_repr, classifier_ckpt = load_model(classifier_path, use_ddim=False)\n",
    "classifier_ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Fréchet Inception Distance (FID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdne.metric import compute_fid\n",
    "\n",
    "fid_train_vs_test = compute_fid(\n",
    "    classifier.get_embeddings(train_dataloader, classifier_data_repr), \n",
    "    classifier.get_embeddings(test_dataloader, classifier_data_repr)\n",
    ")\n",
    "print(f\"FID baseline (train (N={len(train_dataset)}) vs test (N={len(test_dataset)})): {fid_train_vs_test}\")\n",
    "\n",
    "\n",
    "fid_real_vs_generated = compute_fid(\n",
    "    classifier.get_embeddings(real_dataloader, classifier_data_repr), \n",
    "    classifier.get_embeddings(generated_data['waveforms'], classifier_data_repr)\n",
    ")\n",
    "print(f\"FID (real (N={len(real_dataset)}) vs generated (N={generated_data['waveforms'].shape[0]})): {fid_real_vs_generated}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Inception Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdne.metric import compute_inception_score\n",
    "\n",
    "print(\"Inception Score:\", compute_inception_score(classifier.get_probabilities(generated_data['waveforms'], classifier_data_repr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: widgets do not work\n",
    "\n",
    "# from tqdne.metric import PowerSpectralDensity, BinMetric\n",
    "# import ipywidgets as widgets\n",
    "# from functools import partial\n",
    "\n",
    "# metrics = {\"Power Spectral Density\": partial(PowerSpectralDensity, fs=config.fs)}\n",
    "\n",
    "# # Create a dropdown for selecting the metric\n",
    "# metric_dropdown = widgets.Dropdown(\n",
    "#     options=metrics.keys(),\n",
    "#     description='Metric:',\n",
    "# )\n",
    "\n",
    "# # Create a slider for selecting the channel\n",
    "# channel_slider = widgets.IntSlider(\n",
    "#     value=0,\n",
    "#     min=0,\n",
    "#     max=2,\n",
    "#     step=1,\n",
    "#     description='Channel:',\n",
    "#     disabled=False,\n",
    "#     continuous_update=False,\n",
    "#     orientation='horizontal',\n",
    "#     readout=True,\n",
    "#     readout_format='d'\n",
    "# )\n",
    "\n",
    "\n",
    "# # Bin plot checkbox\n",
    "# bin_plot_checkbox = widgets.Checkbox(\n",
    "#     value=False,\n",
    "#     description='Plot bins',\n",
    "#     disabled=False,\n",
    "#     indent=True,\n",
    "# )\n",
    "\n",
    "# # Create a slider for selecting the number of bins\n",
    "# num_bins_slider = widgets.IntSlider(\n",
    "#     value=10,\n",
    "#     min=1,\n",
    "#     max=50,\n",
    "#     step=1,\n",
    "#     description='Num bins:',\n",
    "#     disabled=False,\n",
    "#     continuous_update=False,\n",
    "#     orientation='horizontal',\n",
    "#     readout=True,\n",
    "#     readout_format='d'\n",
    "# )\n",
    "\n",
    "# # Function to update the plot\n",
    "# def update_plot(metric_name, bin_plot, num_bins=10, channel=0):\n",
    "#     metric = metrics[metric_name](channel=channel)\n",
    "#     if bin_plot:\n",
    "#         metric = BinMetric(metric, num_mag_bins=num_bins, num_dist_bins=num_bins)\n",
    "\n",
    "#     # Compute the metric\n",
    "#     metric.reset()\n",
    "#     metric.update(pred={\"generated\": pred_waveforms}, target={\"representation\": test_waveforms[:, :, : pred_waveforms.shape[-1]], \"cond\": test_features})\n",
    "#     metric.plot().show()\n",
    "\n",
    "# # Create interactive plot\n",
    "# widgets.interact(update_plot, metric_name=metric_dropdown, channel=channel_slider, bin_plot=bin_plot_checkbox, num_bins=num_bins_slider)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the data to obspy format\n",
    "# from obspy import Stream, Trace\n",
    "\n",
    "# # Convert waveforms to Trace objects\n",
    "# traces = [Trace(data=waveform, header={k:v for k, v in get_cond_params_dict(pred_data[\"cond\"][i])}) for i, waveform in enumerate(pred_data[\"waveforms\"])]\n",
    "\n",
    "# # Create a Stream object\n",
    "# st = Stream(traces=traces)\n",
    "\n",
    "# # Save the Stream object to a file\n",
    "# st.write(\"generated_waveforms.mseed\", format=\"MSEED\", reclen=512, encoding=\"FLOAT64\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tqdne-kernel",
   "language": "python",
   "name": "tqdne-kernel"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
